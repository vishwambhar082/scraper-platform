# Database Configuration
DB_URL=postgresql://scraper:scraper123@postgres:5432/scraperdb
DB_HOST=postgres
DB_USER=scraper
DB_PASSWORD=scraper123
DB_NAME=scraperdb

# API Security - CHANGE THIS IN PRODUCTION!
# Generate with: python3 -c "import secrets; print(secrets.token_urlsafe(32))"
SCRAPER_SECRET_KEY=CHANGE-ME-TO-A-SECURE-RANDOM-VALUE

# Crypto Key for encrypting sensitive data (cookies, tokens)
# Generate with: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
CRYPTO_KEY=CHANGE-ME-TO-A-FERNET-KEY

# PostgreSQL (used by docker-compose)
POSTGRES_USER=scraper
POSTGRES_PASSWORD=scraper123
POSTGRES_DB=scraperdb

# Airflow Configuration (required for docker-compose)
# Generate with: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
AIRFLOW__CORE__FERNET_KEY=CHANGE-ME-TO-A-FERNET-KEY
AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow

# Optional: Logging
LOG_LEVEL=INFO

# Optional: Test/Local Development
# Uncomment to use SQLite instead of PostgreSQL for local runs
# RUN_DB_PATH=logs/run_tracking.sqlite

# Optional: Browser automation
# Set to 1 to use fake browser for testing (no actual browser required)
# SCRAPER_PLATFORM_FAKE_BROWSER=1

# Python Path
PYTHONPATH=/app
